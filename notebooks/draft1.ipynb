{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "634c8d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # reads .env into environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8818d017",
   "metadata": {},
   "source": [
    "## `Define llm and tools`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bbfbd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-5-mini\"\n",
    ")\n",
    "\n",
    "# # ChatAnthropic\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "# llm = ChatAnthropic(\n",
    "#     model=\"claude-haiku-4-5-20251001\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcf6beb",
   "metadata": {},
   "source": [
    "## `Define state`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bec554e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain.messages import HumanMessage, AIMessage\n",
    "class State(TypedDict):\n",
    "    question: HumanMessage\n",
    "    answer: AIMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a361c0de",
   "metadata": {},
   "source": [
    "## `Define nodes, edges`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df3ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def llm_call(state: State) -> State:\n",
    "#     answer = llm.invoke([state[\"question\"]]) # the value should be a list of `langchain.messages`\n",
    "#     return {\"answer\": answer}\n",
    "\n",
    "def llm_call(state: State) -> State:\n",
    "    answer = llm.invoke([state[\"question\"]]) # the value should be a list of `langchain.messages`\n",
    "    return State(answer=answer)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c886b3c",
   "metadata": {},
   "source": [
    "## `Build and compile the agent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81faa49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGoAAADqCAIAAADF80cYAAAQAElEQVR4nOydCWAT1brHz0yStmm67226UVrZlMUWKbL0SouozwooT7gsXgVEkR1BubJ4UTb1oajgxQqIIogKIiCyySZll7KU3baUAi0p6ZKkTdMkM/POTNo0LUkm6WnqQM4PTZOzTJJ/zjbfWT4xwzAA01zEAIMAlg8JLB8SWD4ksHxIYPmQQJXv+sXavDPqcoVOX0vTRgAaj4IIEjA0DCIah8A/DEHAJ/XhRF1GNpD9R9QlM2eBf2jQJJC9DN0oOyC5R8tAAl6TaXgjDomU9JKKvH1EMe29O/X0BQgQzRv35exXnc+u1GqM8LOKJQQpITw8SfbrUY2uRpBQJxpQRKMQKCjBKUWbQ83fH4ayAtYlq8vCPjJ0k0CCC2Qss7Mp4QUoUwruUpaC1iPxFNE0gL93rdZI04yXt7hNJ9kTL4YC53Favpx9laf3lVM0CJV7ds8Ije3gAe5nNOVM9tbS4nytQU+36ew7YGSYU9mdk2/dwqJqtbFjakDfwUHgweLy8apjvykpmnl1XhvgcJFwQr7/zsgPjfUaMlkOHlwOblJePFbZa2BY175+jqR3VL7l0/P6vRjRMdUHuAFfzMgfNiMuKIK/X3VIvhVv5r26INFDCtyH/76V32NAyKPp/vaTkYCPlW/l9xsa4VbaQcZ/2PbYTqXqrtF+Mh75vnnvRmiMV4fH3KLONiH16ZAfPrlpP409+f78XaWtpl6Y9CD3FXZITvf3lJKbP7tlJ409+eD47pHUAODGDJkcXVKos5PApnznDmpoA937gRvfOYXMXyTzE29ZUWwrgU35zh+piIhv7f6if//+t2/fBk6Sn5//7LPPAtfQuXeAoqjGVqxN+dTl+uSMYNCKlJSUVFRUAOe5dOkScBnJGQEUxRRdsV6FrY8M889qSREZ294TuAA40vz+++9//fXXGzdutGnTJjU1dfz48WfOnHn99ddh7MCBA9PS0pYuXQrL1KZNm06dOlVcXJyQkDBo0KAhQ4aYrpCenj527Nj9+/fDXKNGjVq3bh0MTElJmTZt2ogRI0BLI5WJLxxRxbb3ujfKhnwXqsQuMwVs3LhxzZo1U6dO7dWr18GDB1esWCGTyV555ZVly5bBwK1bt8rlbF8PFYTCzZ49myCIwsLCDz74IDIyEmaBURKJZMuWLY899hgUMTk5GSbYs2cP/D2Aa/DxF5eX1lqNsi6fpswglbrKkpqTk9OxY0dTazV48ODu3btrtdp7ky1evLi6ujoqKgpwJWvbtm1Hjx41yQf18vf3nzFjBmgV/EMkt/KsN3/WNaqtpcSe/DckzaNLly6ff/75e++9161bt759+0ZHR1tNBus4LKdHjhyBddwUYiqVJuAPAFoLLx+R0UBZjbJRxKA9T0QA1zB8+HBYWw8dOjR//nyxWAx728mTJ4eGNrJW0jQ9ZcoUvV4/ceJEWPR8fX3HjBljmcDDo/XsjARr3LWuhnX5JFJJbY11vdEhSXIwR0FBwcmTJ7Oysqqqqj755BPLNFeuXLl48eIXX3wBGzhTiEajCQtzzpbZUtRoaNIp+WS+4sq71htLdGAb36FDh7Zt2yZwQF1gP9AkTWVlJXw061XAAbOAvwN1mUEiFVmNst7AtXnYx6h31dqXXbt2zZw5848//lCpVNnZ2XD8AVtDGB4fHw8f9+7de+HCBSgrrNdwRKJWq2G3+9FHH8HxDRwYWr1gbGysUqmEnbi5lWxZVGV6vwDr5cy6fB16yGiKURbrgQuYM2cOVGf69Olw+Pb+++/DUR4cncBw2IdkZmauXLkSdiwRERELFizIzc3t168fHM1NmDABDvqgrOahnyW9e/fu2rUr7Ih3794NXIBOS3Xobn1Czqa5dPXc69BU9dy4SODeXDml+f17xcSPE63G2hydPPSob3GeFrg9OfsqQuRetmJtjo37DA6BM7lnD6q7/sP6pMmdO3eGDRtmNcrHxwd2plajYLWFtxzANazlsBpFEDbrGRwbWW0TTJQpal9blGgr1t5cx/6Nyrxz6nGLE6zGGo3G0tJSq1E6nc7Ly/ovBjsE140/NBxWo2AX5OdnvRzAcPh7W43asKQITrqPmB0LbMAzVZQ1uyCunWzAS+HA/Si6qtuedWvC0kQ7aXjuzMYtTMg7V6VT0cD92Pl1cZ/BPBWF/8a2//DwrxdeB27G1+8Wytt6d+7NM1nu0DxvhcK44YPCCR8nAvcATvKmvRDesQf//KKjqwyuX9TuWF3cpW9gn0GtaoJuZYou1/y2tiS2nfczoyMcSe/MEiEKfDWvQCQmn/5XZGSCSwzRfy8bPrypUup7ZoZ17ePooj+nF6j9tvpO4ZVqqUzUtrNP3+dDwP3P2UPq3COVmnJDcKTn0DejncrbzOWRO9cqbl6tNhoZsZiQ+Yk8pCIvmYgQNVoeCQ1TNEOb15uSIna9Is314aaFjiTXb9G0OX3dc5Jd+gg/Vt1iSPiSAdzHZNjnNBcoEhEU915iCWk00Nz1AU2xtjl2PSnNsB+GWx3JLcbkLle/ulLsIaqtoWvUlLbKCO1y8IOFRHoOeV0OnK9RzZTPhLYcHN+jvFusU5fpuW9F0o1Wl9KWPTvB/V/3bgS3ApezoZnfn6hbWcqYjWvwJbSbikQkm4RLBoU1LSi10BFQlCmEVZ/LCr8Tu7yXNfqSJCscd2XuvoON9pCQhBh4eYsCwySdHw+Ut2t+Q4QkXyswYMCADRs2BAcLtL8S+sp6eGsI7/OAUMHyIYHlQ0Lo8hkMBjgpDoSKoOWjuYEMSbpqxhkdQcsn8JoLsHyICPrDCbzhA7j0IYLlQwLLhwSWDwmhy4e7juaDSx8SWD4ksHxIwGEzlq/54NKHBJYPCSwfElg+JLDFBQlc+pAQiUS+vkhnTLkaoU8VqVQqIGCEXTXEYlh/gYDB8iGB5UMCy4cElg8JoQ9csHzNB5c+JLB8SGD5kMDyIYHlQwLLhwSWDwksHxJYPiSEL58QdxXNnz9/27Ztpg/G7a9iIUny1KlTQGAIcdH6+PHj4+PjSQ542wsfoXy2Dlr7exGifGFhYRkZGZYhUL6BAwcC4SHQLRMjR46Mi4szv5TL5YMGDQLCQ6DywQm2zMxM84aYJ598MiBAiCdIC3fDzvDhw03tXVRU1PPPPw8EiXM97/FfyyvLDYZadv+xyXOQ5SMLye10rnd9w7D7kYHFlnJAigna2NSLTsPViEZ5b9++/VfeNXlUdFJSEjBveK5/L/Pu8zpXSOZt1SQbYLFJnY2m6zamN4Sb38scKJGQUpmk99PBIoeP6HdUvp1fKwovVYskBCkCBp2FhyDTI1nnD4jz1WTheMn0bRlgsSWf3TJv/p4NUZZXq88L2L3jFMnuq69PTzfyTMTYkA+ARk6hQOMfiX1JcJkaX4f9diTQ1zIBYR7DZzrU0Tsk39Ht5ReOqTJfjfcJctWBpoJiy/JbMhnxwlR+Xwf88h38QZl3oXrojDjgTmxfeYsUMcNmxNhPxt91/HW+qkP3QOBmZI6OrlDoAd/xtzzyUXoAO4rOaQ75PXqg8IBNIXliV7n9VDwmA1UZRbur/2OaYqo1PMWPz+JCUIw7Hj7HQlEMZeQpOtjFJxJYPpsQBAP4xmlYPjsQWL7mw3aZfO0+r3xucZvRbHjlc9NRC6g78g33vM2FIfjLDpbPNuwBjDxtF5bPJtxBlDxpsHy2YRjefpNXPtJtu1627vI1frwGK9rZrnfzzxsznuxhej7o+Yxv160CfxMFBXlPpKfk5p6Fz/8z/+0ZM99wKjtbefnkwZXXJi0ybHZnGKGUvi2//Ljuu1UfLlk+e+60sjJlXFybN6fNrqysWLxknpEydk/pOX3aOwEBPDZttUb95Zef/rZzq79/QEpyj1fHTgoPZ49GP3bs8P4Du8/nnlGrVR3aPzxq1NhuXVNAC0Dwlr5WmueVSCRVVZq13375fx9+sX3rQYPBsGjJvJ27tq36auP6dVtzL5z94cd19q9gNBpn/Xuysuzux0tXTpo4s/SuYtY7k2GgTqdbuHhObW3trLfnL1q4LDY2fvacaeXlZaBVaL3KCyX710vjYmLYKacej/X6ecvGz5atCgpiD2Tu2iU5P/+a/ezHT2Rfvnzhm683QYHgS3idH3/6DsoUFha+KmujVCqFRRKGw9K3ddsm+Huk9U0HrqdVTQbxcXV+e7y9vQMDg0zaQaRSb0XpHft58/P/grlM2kEeSmo/550FpudabfWq1cvPnjsNmwVTCGwWQKvAW3lb0mRg6enRltdHW1RXV3l6WvF/pFDcmTJtLCzac2cv2rPr2N7dx0ELwd11PCgmA29vWU2NlqbpJgfpHjy0V6/Xw4YP1l/QouWOWwHB8xvzlj6h3HS0b9cR9hJXr102vSwqKpw6fRys0bC39fX1M2kHOfTHPtBSQIsLX+lr1cqLQkpKqlwek5X12eHsA6f+PL7s0yV3SxVwAJSQkASbvG3bN8Ne+MTJozk5J2EfUsrXkjqEAxYX4S5Qa4JYLIaDHpqh57078623J3pJpYsXfQoD0/sNGDVyzLfrvuo/IHXz5g2TJ73VP+OZDd+v/fiTRcD18KxxKb+jX/9B0cv/SQTux7oFeQ91880Ybs9HHb5pswm0VzH0/WMuhaaRd2ZPtRX73bpfTANjQSGgmbZHHumalbXBVqwAtQNCm2mLjIgCggEb65GwXFNsCywfElg++6De87rvIg3Y9hEk6sDFfRdpsD738FyHS8HyIYHlQwLLhwSffJSHyF0V9vASSTxE9tPw2PuC5LD/JssVgj6PwUVQRjomydt+Gn5zqY+/+M9dpcDNuHhURZJE225S+8n45Rs1O1Z5S3fzoh64E2cOlPfODOdN5uh+3qx/F8h8JTEdfPyCxcZ799ow1m9POCfQjUJIQNCsY+gGp9ANe3htBJAWK3UI045oq1HcxzC93b0fp0lKq9+Z3cyrA0WXNWUltS/NipMF8TR8wKnd5Js/Ky5X6I0Gymi4Nwu7v/je0EYyWYRYhjdJ08TjdpMEJOdfnLEWRXAeyJm6C9Tvqq7fKV73vpywlvuvLS8iIlm35bCxeu6VGB/+ksflFbhz7aeeemr9+vXYuXYzwe6NkcDyISFwb0+49CEhaPlgt0bTtEjEP4D4u8DeYpDA8iGBXT0hgUsfElg+JLB8SOC2Dwlc+pDA8iGB5UMCy4cElg8JLB8SWD4ksHxI4GEzErj0IYHlQ0Lo3mJCQ0OBgBG0fBRFlZYKenUS9lWEBJYPCSwfElg+JLB8SGD5kBC6fHDsAgQMLn1IYPmQELp80OgCBAwufUhg+ZDA8iGB5UMCy4cElg8JIe4qmjRpUnZ2tvl0TpIkaZqGL0+fPg0EhhDP75syZUp0dDRZD+AUjI2NBcJDiPIlJib27t3bslrAopeWlgaEh3Cda8fENLjXhM+HDBkChIdA5ZPL5enpdedWw4YvJSXF5ClaaAj37NJhw4aZvLvDx6FDhwJB0pIDsPbX0AAABqBJREFUF1Wp8W5xrV5H0fV+nhmCc8Ns2bfXe4FmGlzw1e/9Nrt9rvvr2f/xMQd1hx5p93DN3dDcUnXDBnFTDtNbWG4cJxq7mG7yVUlAiMjACI+waA/QQqAOXK7laHN+Lyu/q6eM7NiCOzKQoCnzNWlrBZz7ivUb9e/dON8QQnDy3LPPn2j+0VqM6bxysYT0CxQnPerb/Ukk18PNl+/AJuXVEypY0MReIlmANCjaT+rfYr+qSzHomYqb6upyra5KD2uBPFH63GvNPLWyOfKVF+l/XH4LZguI9Itsf387jq68rVUUlFEGKvmJ4B7POH08qtPy7V1fevW0OijKP6pTEHhQqCzWlly56xcsGTErxqmMzsm3/wfltTOa9mlCvAFA56+jtyVi5uV34xzP4oR8Py8vvlOk6/iEE1e/72AVJOmX58c7mN7Rcd+O1XcUtx5w7SBJj8uBSPzNgiIH0zsk3/ULNYWXqjukPeDamYjvHqmrMu5cq3AksUPy7f6uJLSNEA/tdhHt0uIKcqscSckv3841CoIUhbV1I/kgUn+vb967wZuMX77CK1WhCff34K4ZJHSPqFIbVaU8S0R45Du+oxz2zkFyGRAkVdUVM+b2OJv7O3ABHlLxng0l9tPwyHc1R+Ppc3/cirU4gZF+ZSU8pxbyyKfVUEFyf+CWhLTxMxqZijv26q89g1WlgqFpJiCK5/zOZqPWlG3fuazw5nm9XtcuKTUjbXRYKDs2KlHkL10+fPJra/b/8c2Fy4f8/cK6PtL/mf4TTMcJnTm/Z9e+L2tq1B3b90nrNQK4ErGIzM2u7DvE5vF39kpf/gW1685cpyhq5Zo38gtzXsic9ebEDT6yoM+yRivLbgH2Q7MbsX7aurhb5wFL3s0ePmT+oSPrz11kG7gSRd6GTfNSuj0za+rmlK7/s3XHUuBSRGRpSY2deHvyqe7qXXfi//Wis6XKwn8Omd/+oZ5+vsGZT02WeQccPrbRnKBLp35dHk4XiyVt2zwaHCi/dfsKDDx6YnOAf0T/f4zx9vZLTEjukTIIuBSCrlHbm2i2V3lZq6fLZoELb5wTiSRJCXWeYKENE8pUUHjGnCA6qoP5uZeXb41OA58oy29GhCeYw2PkHYErYc/lpOyVIHvykWLCZXUX1OiqKMoAhx2WgT6yhgEmQVipGVqtOiS4wabk4cFzMDAqDEFKmitfaJQncBm+PsHwy48e0ajxauJ/8l5gnTUYdOaXtbXVwKUwwNff3o5Ye/I9lOx3aIurtpTJIx/S62sCAsJDgupmIMvKb1uWPqsEBkReunLY7Ojz0tVs4Epoig6PtVeG7P3ant7QeEMqb2iAC0hq2719Us+ffllYUXmnqrryyIlNn658+WTOdvu5unTKgHcav+xYCs2UeQWnj57YBFwJRdFd0u0Z1XkmKn0CxKoSTUicL3ABo0d+fOzUz9/9OOfGzdzQkLhHuzzVpyfPfG67pB7PDph07OTPM+elwi54xP/OX7HqNRe5tFFcrRCLSand1pXH2nz+sDp7q7JjultY+ppw9fDN8GiPQW/Ym4Tjaao79/EjRUCRVwncD4POaF874Mgqg3bJfldPq8ITrdv7YCs+b3F/q1FGox6O7Kw60Y4ITZg47ivQcqxeN/160TmrUQZDrURipfn3kHjNe2sHsEH+8ZKgCP6Bh0NTRVnvXJcFessfDrEaq1YrrYbX6ms8bYzLRCKxTNaS9tdqrYoyWt8BUlNbLfW0ZnAjCHi3Yz2L2lhw8uaEpYmAD4fk02vBV3PzO2XEA/fg0v7CLn0Cez3HP5Ht0FyHhzd49IngS/sKgRuQd/R2iNzLEe2A4xOVPZ8NSE4PuvigK3jpwI3AcNGLU+UOpndulcHZQ+qj2+62TZV7+gj6cJ/mcfVQkV+I+J8znFin4fQalzMHKrO3Kb0DvNo+FgkeFIovl1fcUse2l2WOi3AqYzMXqK2ae722hpYFeMUnO/d+QgMKp7qjgWPbQa9Fh8c7PavT/PV913K0R7aWwtk8eF/s6S32DfXxDZdJfQTvwaKG0ihrNEqtTlNrrKUkXkSn1AAHO4p7Qd4WQ4Pf1ipu52v1OoqpW1pL0K201eaehakNropsZiFI+I/w8BSHyCWpTwdHtEEyyrX8rqKaKtZSUX95i9t5ot7RlQlLL0zwv7rnXBRT7xjc5OCVhLHcVczurkxPuIXA9VHc1UhuzTRT/9K0/pmufykCUpmoZacfhO7qSeBgF59IYPmQwPIhgeVDAsuHBJYPif8HAAD//5Jjd1oAAAAGSURBVAMAved4xI44zlsAAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "# Build workflow\n",
    "agent_builder = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "agent_builder.add_edge(START, \"llm_call\")\n",
    "agent_builder.add_edge(\"llm_call\", END)\n",
    "\n",
    "# Compile the agent\n",
    "agent = agent_builder.compile()\n",
    "\n",
    "# Show the agent\n",
    "from IPython.display import Image, display\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32de035d",
   "metadata": {},
   "source": [
    "## `Test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ecca7e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid input type <class 'langchain_core.messages.human.HumanMessage'>. Must be a PromptValue, str, or list of BaseMessages.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m    \n\u001b[32m      7\u001b[39m input_state = State(\n\u001b[32m      8\u001b[39m     question = HumanMessage(content=user_question)\n\u001b[32m      9\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m output_state = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m output_state[\u001b[33m'\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m'\u001b[39m].pretty_print()\n\u001b[32m     13\u001b[39m output_state[\u001b[33m'\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m'\u001b[39m].pretty_print()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/studies/langgraph-jupyter-template/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/studies/langgraph-jupyter-template/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:2643\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2641\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2642\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2643\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2653\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/studies/langgraph-jupyter-template/.venv/lib/python3.12/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/studies/langgraph-jupyter-template/.venv/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/studies/langgraph-jupyter-template/.venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/studies/langgraph-jupyter-template/.venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mllm_call\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mllm_call\u001b[39m(state: State) -> State:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     answer = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m State(answer=answer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/studies/langgraph-jupyter-template/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:399\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    398\u001b[39m             \u001b[38;5;28mself\u001b[39m.generate_prompt(\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m                 [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m],\n\u001b[32m    400\u001b[39m                 stop=stop,\n\u001b[32m    401\u001b[39m                 callbacks=config.get(\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    402\u001b[39m                 tags=config.get(\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    403\u001b[39m                 metadata=config.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    404\u001b[39m                 run_name=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    405\u001b[39m                 run_id=config.pop(\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    406\u001b[39m                 **kwargs,\n\u001b[32m    407\u001b[39m             ).generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/studies/langgraph-jupyter-template/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:382\u001b[39m, in \u001b[36mBaseChatModel._convert_input\u001b[39m\u001b[34m(self, model_input)\u001b[39m\n\u001b[32m    377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages=convert_to_messages(model_input))\n\u001b[32m    378\u001b[39m msg = (\n\u001b[32m    379\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid input type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model_input)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    380\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mMust be a PromptValue, str, or list of BaseMessages.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    381\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[31mValueError\u001b[39m: Invalid input type <class 'langchain_core.messages.human.HumanMessage'>. Must be a PromptValue, str, or list of BaseMessages.",
      "During task with name 'llm_call' and id 'b9d33e9c-d595-2b8d-8f1d-298fa9444989'"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_question = input('ask a question: ')\n",
    "\n",
    "    if user_question.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        break    \n",
    "\n",
    "    input_state = State(\n",
    "        question = HumanMessage(content=user_question)\n",
    "    )\n",
    "    output_state = agent.invoke(input_state)\n",
    "\n",
    "    output_state['question'].pretty_print()\n",
    "    output_state['answer'].pretty_print()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97473d16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-jupyter-template",
   "language": "python",
   "name": "langgraph-jupyter-template"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
